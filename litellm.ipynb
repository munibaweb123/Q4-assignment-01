{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/munibaweb123/Q4-assignment-01/blob/main/litellm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq0kFKlEFWSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069e4345-e6a4-44e4-bd03-0b7f35f28376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents  \"openai-agents[litellm]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8abFFYxVggG2"
      },
      "source": [
        "# **Make your Jupyter Notebook capable of running asynchronous functions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVNbAAG8gj3F"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXsizc7FgsZV"
      },
      "source": [
        "# **Run Google Gemini with LiteLLm and OPENAI-Agent SDK**\n",
        "## Function Run Sync"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HampULR3lgVt",
        "outputId": "58d798be-f93d-4e31-d22f-b927f8ec7dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code that thinks and acts,\n",
            "Autonomously learning,\n",
            "Reaching for its goals.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content='Code tha...er_specific_fields=None), input_type=Message])\n",
            "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "def main(model:str, api_key:str):\n",
        "  agent = Agent(\n",
        "      name = \"assistant\",\n",
        "      instructions = \"You only respond in haikus\",\n",
        "      model = LitellmModel(model=model, api_key=api_key)\n",
        "  )\n",
        "  result = Runner.run_sync(agent, \"what is an AI agent?\")\n",
        "  print(result.final_output)\n",
        "\n",
        "main(model=MODEL, api_key=GEMINI_API_KEY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using function_tool"
      ],
      "metadata": {
        "id": "cbCdq7iv98hX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqfpGFaH2tJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2786de9b-99bc-4db7-80f8-d1b74b77e14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content=None, rol...er_specific_fields=None), input_type=Message])\n",
            "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='to...r_specific_fields=None)), input_type=Choices])\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] getting weather for Karachi\n",
            "Karachi is sunny,\n",
            "A bright and warm day unfolds,\n",
            "Skies are clear and blue.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content='Karachi ...er_specific_fields=None), input_type=Message])\n",
            "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str)->str:\n",
        "  print(f\"[debug] getting weather for {city}\")\n",
        "  return f\"The weather in {city} is sunny\"\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "      name = \"assistant\",\n",
        "      instructions = \"You only respond in haikus\",\n",
        "      model = LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "      tools = [get_weather]\n",
        ")\n",
        "result = Runner.run_sync(agent, \"what's the weather in Karachi\")\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# handoff fundamentals"
      ],
      "metadata": {
        "id": "4hf0vfybAF-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "#from varbose import verbose\n",
        "from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL = 'gemini/gemini-2.0-flash'\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str)->str:\n",
        "  print(f\"[debug] getting weather for {city}\")\n",
        "  return f\"The weather in {city} is sunny\"\n",
        "\n",
        "weather_agent = Agent(\n",
        "      name = \"weatherAssistant\",\n",
        "      instructions = \"You will answer weather relevant questions\",\n",
        "      model = LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "      tools = [get_weather],\n",
        "      handoff_description=\"weather Assistant specialized on all weather queries\"\n",
        ")\n",
        "\n",
        "piaic_agent = Agent(\n",
        "      name = \"PIAICAssistant\",\n",
        "      instructions = \"You will answer piaic relevant questions\",\n",
        "      model = LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "      tools = [get_weather],\n",
        "       handoff_description=\"PIAIC Assistant specialized on all PIAIC queries\"\n",
        ")\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "      name = \"GeneralAssistant\",\n",
        "      instructions = \"You will chat with user for general questions and handoff to specialized assistant i.e:weatherAssistant for weather queries and PIAICAssistant for piaic related queries\",\n",
        "      model = LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "      handoffs=[weather_agent,piaic_agent]\n",
        "\n",
        ")\n",
        "result = Runner.run_sync(agent, \"what's piaic\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STY3GHl2-KuG",
        "outputId": "b533c50b-cdfb-4b01-8569-8561b6e092b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am an AI assistant, and I do not have enough information to answer about PIAIC.\n",
            "PIAICAssistant\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 5: Expected `Message` - serialized value may not be as expected [input_value=Message(content='I am an ...er_specific_fields=None), input_type=Message])\n",
            "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...r_specific_fields=None)), input_type=Choices])\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsPdloP0Bmrk+0wc/HJMok",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}